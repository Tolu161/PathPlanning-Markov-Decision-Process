# MDP-PathPlanning-
COMP 3004 Coursework Coppeliasim code 

This study evaluates the effectiveness of Markov Decision Process (MDP) strategies, specifically Policy Iteration and Value Iteration, for improving path planning in Search and Rescue (SAR) operations using autonomous mobile robots. The research explored variations in performance by manipulating environmental configurations and reward placements within a Gridworld simulation. 
![image](https://github.com/user-attachments/assets/23217b5c-f5dd-4bea-a9b8-53a2169aa50a)

![image](https://github.com/user-attachments/assets/43eae4e0-fe21-4ac2-8d3b-21dcaea38f31)

It also assessed the impact of transitioning the operational model from stochastic to deterministic on algorithm performance. The main performance metrics included response times and efficiency under different simulated conditions. The findings indicate performance differences between Policy Iteration and Value Iteration, particularly in their responses to environmental changes and reward adjustments.

![image](https://github.com/user-attachments/assets/076d407a-c0df-46aa-958e-067c7345d1b0)

![image](https://github.com/user-attachments/assets/48c74a3c-b58e-45df-997d-559883cfb375)

Modifying the model from stochastic to deterministic significantly affected the policies generated by Value Iteration, presenting challenges in adaptability. Although initial attempts were made to extend the evaluation to a 3D environment using Coppeliasim, time constraints limited the thorough examination to 2D scenarios. This highlights the need for further research to assess these MDP approaches in more complex three-dimensional settings, which could provide insights into their practical application in real-world SAR scenarios.

![image](https://github.com/user-attachments/assets/39fbd5cd-dc02-4be5-8d91-1e30bb45b3b3)
